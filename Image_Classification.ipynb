{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPWc9fnnzBpbPFfO9VxSVvI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varunkr24/AIML/blob/Python/Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlspsTFtIDZD"
      },
      "source": [
        "import numpy as np\r\n",
        "import h5py\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hJSkwL8mu1it",
        "outputId": "b6a5a947-31d3-49af-99e6-fea698bc4713"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "import tensorflow\r\n",
        "tensorflow.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhUUU114u8Hr"
      },
      "source": [
        "import random\r\n",
        "random.seed(0)\r\n",
        "\r\n",
        "# Ignore the warnings\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoxJ1u1wG5xJ",
        "outputId": "2ae0b57c-8e4d-4038-b895-ac69e1d8ae3d"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98RwSg2fG7Pu"
      },
      "source": [
        "path = \"/content/drive/MyDrive/AIML/Projects/NN Project/NN Project/Autonomous_Vehicles_SVHN_single_grey1.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUKBzn5VHo3T"
      },
      "source": [
        "f = h5py.File(path, 'r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nsWgSxIVw_v",
        "outputId": "645c51d2-018b-48c8-bf81-bebc8c8debe6"
      },
      "source": [
        "list(f.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RgcAM-TcgPv",
        "outputId": "60fbe53c-7d5a-4d5f-ac0e-eb428019d048"
      },
      "source": [
        "f['X_test'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18000, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpDgKX_hVhwT",
        "outputId": "6d703d3d-3acb-4f9c-95fe-d81ece5cf73d"
      },
      "source": [
        "f['X_train'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42000, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "PzEGDFecpavb",
        "outputId": "caa905b6-9995-4f0c-d3f3-eb0ece5009f6"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "print(\"Label: {}\".format(f['y_train'][8000]))\r\n",
        "plt.imshow(f['X_train'][8000], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f043944eb90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXLUlEQVR4nO2dW4xcVXaG/2XjC6Yb39puGmjbtAEhMwoGtSyiQSMyw4wIGgmQIgQPiAc0HkWDFKTJAyJSIFIemCiAeIiITLCGiQiXDCCsCCVD0EhoeGBoc7GNG4wxttt2+4rb3eC7vfJQx1KbnPVX966qUz3e/ye1unqv2ufs2nX+rqr911rb3B1CiAufae0egBCiGiR2ITJBYhciEyR2ITJBYhciEyR2ITLhokY6m9ntAJ4BMB3Av7n7E+z+XV1dvmTJktLY2bNnw36nT5+e9NimTYv/j110UfywzSyMRTYlGzuLMduTxc6cOTPp87HHlRpLIdXqTZ3HiKrng40xOia7TqdPn17aPjQ0hEOHDpUeMFnsZjYdwL8A+DGAXQA+MLN17r456rNkyRK89957pbGxsbHwXAcPHixtZ4Lu6OgIY/PmzQtjs2bNCmOnTp0qbT9+/HjY5+jRo2Hs5MmTYezEiRNhbHR0NIwdO3astJ1dODNnzgxjbI5ZLOUfI/snxuaDzWM0jkgsADBjxowwxuaK/SNgjy2ax+7u7rBPZ2dnafttt90WnyeM1GcVgK3uvs3dTwJ4GcCdDRxPCNFCGhH7FQCGxv29q2gTQkxBWr5AZ2arzWzAzAait+NCiNbTiNh3A+gd9/eVRdt5uPsad+939/6urq4GTieEaIRGxP4BgGvM7CozmwngXgDrmjMsIUSzSV6Nd/fTZvYQgP9BzXpb6+6fph6PrWRGq5VsNbhK2NjZyi6DPTa2shuturPV59RYig3FLChmsbJ5jFwSdj72uJhzwcbR7NV4dq6Ua78hn93d3wLwViPHEEJUw9R4aRRCtByJXYhMkNiFyASJXYhMkNiFyISGVuMni5mF9kSKFdKKYpkpFmCqvcaSbtg45syZE8ZSMgTZudjxWD9mX6Wci8WYrRVdI6mJQawfux5T7EF2faSgV3YhMkFiFyITJHYhMkFiFyITJHYhMqHS1XggLVEjJRGm2UkEAB9jyrlSY2y1OFq1TlmxBtLciXqxlHGkxiJS68yl1gZMTQBqJnplFyITJHYhMkFiFyITJHYhMkFiFyITJHYhMqFy6y2CWTUplhdjqmwl1GzripFqXTELM3UbrakOuz5YQgvrl2LnNTvRS6/sQmSCxC5EJkjsQmSCxC5EJkjsQmSCxC5EJjRkvZnZdgBjAM4AOO3u/ez+7o7jx4+XxqJ2IM4KSq1LxmwtZnecOHFi0udilgvLXmN15tgxI5uSjZFZRiyW8rhTs8ZSM8oiUuawHil194DY3kyxX2ldwEkf7f/zF+6uvZiFmOLobbwQmdCo2B3A78xsvZmtbsaAhBCtodG38be4+24zWwzgbTP7zN3fHX+H4p/AagDo7e1t8HRCiFQaemV3993F7/0A3gCwquQ+a9y93937u7q6GjmdEKIBksVuZpeYWee52wB+AmBTswYmhGgujbyN7wbwRrHUfxGA/3D3/2Yd3D2pIGIUi6wwADh27FgY++abb8IYs5rGxsZK25ltyGyhiy++OIx1dHSEsRRLJtVea3bBzNRsOJZtxq6diNmzZ4exSy+9NIyx54xZqVVtb9YS683dtwG4IbW/EKJaZL0JkQkSuxCZILELkQkSuxCZILELkQmVFpycNm0atTwiImuL2WsHDhwIY0NDQ02NjY6Ohn1SbS1m46QUuGTnYtlazGpKsQA7OzvDGLO8Tp48GcZY9uOsWbNK29kXvJYvXx7GFi1aFMbY+Jn1Fj3XbK6ix0Xt0DAihLigkNiFyASJXYhMkNiFyASJXYhMqHz7p2i1MGVll63GHzp0KIxt3bo1jA0ODoaxnTt3lrYfOXIk7JOSpAHwJAi2+hz1YyvuqUkh7JjRGC+55JKwD6u7x55r5nhEK9p9fX1hn2ilG+AuCYuxx93spKHwPE09mhBiyiKxC5EJErsQmSCxC5EJErsQmSCxC5EJlVpv7h4mNLBEhygR5ujRo2GfqF4cwBNXWL/IRmNJDtHWPvVgde2YnRfV5WM2GbM9mc3HiMY/MjIS9mE1BQ8fPhzGmE3Z09NT2s5ssquvvjqMsVp47LlmSS2R9ckeV6QX1kev7EJkgsQuRCZI7EJkgsQuRCZI7EJkgsQuRCbUtd7MbC2AnwLY7+7fK9oWAHgFwDIA2wHc4+6xNzIBWIZPZJMwO4nFmO0yf/78MBZZJOx48+bNC2PM8mJWJNu+KurHsq5Y1ht7bMzmiWzR4eHhsE+UVVjvXIwok27u3LlhH5bpx2Jsyy42x5F1m7plV8REXtl/DeD277Q9AuAdd78GwDvF30KIKUxdsRf7rX/9neY7AbxQ3H4BwF1NHpcQosmkfmbvdvdz78f2orajqxBiCtPwAp3XPkyFH6jMbLWZDZjZwMGDBxs9nRAikVSx7zOzHgAofu+P7ujua9y93937WWF+IURrSRX7OgAPFLcfAPBmc4YjhGgVE7HeXgJwK4AuM9sF4DEATwB41cweBLADwD0TPWFkM7CMoWgLImZ1MGuluzteYkjJYFu8eHHYZ9myZWGMFVhk1hsrvhhlqbH5YAUWv/322zDGstQi623z5s1hH3YNMOuKWZgrVqwobb/++uvDPkuXLg1j7Llmti27riJbkW7llFCgta7Y3f2+IPSjSZ9NCNE29A06ITJBYhciEyR2ITJBYhciEyR2ITKh8r3eIpuBFTaMiheywossW4vZUIwoc+zyyy8P+yxfvjyMsSKEKUUlWT/2mNlcsaKerChmlJnHrDyWEceyIllG3w033FDaHllyANDb2xvGUrMYWdZeSiHTlP3h9MouRCZI7EJkgsQuRCZI7EJkgsQuRCZI7EJkQuXWW1QoL8VqYtYEs5qYdcUy0aLsu0WLFoV9WA4/s4wYLCMusjBZhiDLemNWE7PeDh06VNrOCjay+WCZimyOr7322tL2vr6+sM/ChQvDWHQNANz2YtZydO2zoqnsXBF6ZRciEyR2ITJBYhciEyR2ITJBYhciEypdjTezMOmCrcZHK+Sp2y6xlWm2whyt/qeuMLOVXZY4wRIuolVftrLLjsccj1OnToWxyDFgiTWsth6bD1afLnqumeuSugpOk1DIHEfXPnNdonPR6yaMCCEuKCR2ITJBYhciEyR2ITJBYhciEyR2ITJhIts/rQXwUwD73f17RdvjAH4G4EBxt0fd/a0JHCu0clLqbTHritkxzA5jdlJkkbBti1ph47DzRXOVsl1QPZg1dOTIkdL2qDYdECdJAdwqY0lP0TXC5pDNPbO2UonOx5JnIhq13n4N4PaS9qfdfWXxU1foQoj2Ulfs7v4ugK8rGIsQooU08t7uITPbYGZrzSzevlIIMSVIFfuzAJYDWAlgGMCT0R3NbLWZDZjZwIEDB6K7CSFaTJLY3X2fu59x97MAngOwitx3jbv3u3s/q+gihGgtSWI3s55xf94NYFNzhiOEaBUTsd5eAnArgC4z2wXgMQC3mtlKAA5gO4CfNzoQlvUWZUOx2mnMXkut/RZlxDHLiNknqfYas/OYhRnB7BpmRY6MjISxffv2lbazrEKWjcjqzPX09ISx6Jgp8wTw57oVGXERKRZgXbG7+30lzc9P+kxCiLaib9AJkQkSuxCZILELkQkSuxCZILELkQmVFpx099DKScnwYZYFi7FClSnb6qRs7VPvXKkFIqMYGwcrArl3794wtm3btjC2ffv20naW9cast9QttqLsx5TnuR7MDkuNNRO9sguRCRK7EJkgsQuRCRK7EJkgsQuRCRK7EJlQqfV25swZjI6OhrGIyCpjFhqzp1Kzk6LzMeskdf8y9thYxlZ0TDa/hw8fDmODg4Nh7LPPPgtjO3bsKG1nY1+8eHEYS7XeoszI1Cy01GKUzJ6NYuw5i86lvd6EEBK7ELkgsQuRCRK7EJkgsQuRCZWuxk+bNi3cjufEiRNhvyjGth9ix2OrrSn13dgKc0qCD5CeOBGtFrM+rK4aWxFm9emi87GtmpYuXRrGrrrqqjDGatCl1JpLdWsY7JqL5v/gwYNhnyihiF73YUQIcUEhsQuRCRK7EJkgsQuRCRK7EJkgsQuRCRPZ/qkXwG8AdKO23dMad3/GzBYAeAXAMtS2gLrH3eOMitqxQustxWpi1huzXNjWSiwBJRpH6pZAqXZYCux4qTYfm8doi63u7u6wT19fXxhbsmRJGJs/P94xPNpuiiaMJNY2TCW6jqNkIgDYtWtXaTtLvJrIyE8D+KW7rwBwM4BfmNkKAI8AeMfdrwHwTvG3EGKKUlfs7j7s7h8Wt8cADAK4AsCdAF4o7vYCgLtaNUghRONM6j2JmS0DcCOA9wF0u/twEdqL2tt8IcQUZcJiN7MOAK8BeNjdz6tA4bUPQKUfgsxstZkNmNkA+/qfEKK1TEjsZjYDNaG/6O6vF837zKyniPcA2F/W193XuHu/u/eziiJCiNZSV+xWW05+HsCguz81LrQOwAPF7QcAvNn84QkhmsVEst6+D+B+ABvN7OOi7VEATwB41cweBLADwD31DmRmoRXFrKEok4fZIMxaYbYcs8qY1RfR2dkZxljW2LfffhvG2BgjOyyyoAC+xdOmTZvC2J49e8JY9LjZFk9srqJacgB/PqNrJNXaZP1S6swBcQbbli1bwj6bN28ubWfXTV2xu/sfAERX14/q9RdCTA30DTohMkFiFyITJHYhMkFiFyITJHYhMqHSgpPuTi2xiMg+YRZUahHFVPskIsr+AniGUorNx4i23QLiDCqAb/E0NjYWxq677rrS9tmzZ4d9mL2WarNG10iq/cquK2alskKQIyMjpe1ffPFF2Gfjxo2l7Y1mvQkhLgAkdiEyQWIXIhMkdiEyQWIXIhMkdiEyoXLrLcq+YlbIwoULS9uZzcBskEOHDoUxVnByzpw5pe1REU2A2zjsXMyyY/0ii4fZa1999VUYi2whgFtekcXG5orZcil78NU7ZgSz+Zhty2y5o0ePhrEDBw6UtrNsxKGhodJ2ZtnqlV2ITJDYhcgEiV2ITJDYhcgEiV2ITKh8NT5asWQroFGCBFsZZYkHLMaSXaIVcrZSzGCryGzFnRGt+rJ6cWylns3V3Llzw1i0JdOll14a9mGPudmJMCkJWfXGwWJslTxKKGLJS5FLwjShV3YhMkFiFyITJHYhMkFiFyITJHYhMkFiFyIT6npGZtYL4DeobcnsANa4+zNm9jiAnwE49y3+R939rdSBMCskijGrg9k4LEmGjSOy2Ng4WgGzw44cOVLaPjw8XNoO8MSgaDspAFi8eHEY6+3tLW1nm3uyc7Ekk5R6fakWWsrWW/WOGT221KSbiIkYxKcB/NLdPzSzTgDrzeztIva0u//zpM8qhKiciez1NgxguLg9ZmaDAK5o9cCEEM1lUu8/zWwZgBsBvF80PWRmG8xsrZmVf2VKCDElmLDYzawDwGsAHnb3UQDPAlgOYCVqr/xPBv1Wm9mAmQ2wz4ZCiNYyIbGb2QzUhP6iu78OAO6+z93PuPtZAM8BWFXW193XuHu/u/dHFWeEEK2nrtittvz4PIBBd39qXHvPuLvdDWBT84cnhGgWE1mN/z6A+wFsNLOPi7ZHAdxnZitRs+O2A/h5vQO5e2h7MUsjsi1Y1lhUL67euVJIybpqJBbZawCwc+fO0nZmvbFafiyz7fLLL590bMGCBWGf1OzBFBsq1S5lzwu7HlksetypxwvPU+8O7v4HAGWPMNlTF0JUj75BJ0QmSOxCZILELkQmSOxCZILELkQmVF5wMspQSrE02FZCUZHKejFm40RjZEUqU7OrmJ3HtgXasmVLafu+ffvCPiy76sorrwxjS5YsCWNRRlxHR0fYJ9V6S7E+m22/1jsmu+aiQqbMPo62taLXWxgRQlxQSOxCZILELkQmSOxCZILELkQmSOxCZEKl1tu0adNCy6BevzKYVcOygphlx4pRMostghUhZLCikl9++WUY+/DDD0vbh4aGwj7sOVm0aFEY6+npCWPz5s0rbWdzn2qHMestunbYuVKzGFOKlQLxnDDrLbLrZL0JISR2IXJBYhciEyR2ITJBYhciEyR2ITKhcustsgxYtllkeTEbJCV7DeCWXTQOljXGjnf8+PEwxmrsDw4OhrH169eXtjMrb/ny5WGM7ed22WWXhbHINkoplAikF+eMYDYZu3ZSilsC3HqL5ooV54yelz179oR99MouRCZI7EJkgsQuRCZI7EJkgsQuRCbUXY03s9kA3gUwq7j/b939MTO7CsDLABYCWA/gfncvLzB3/vFK29nqaJScwpJW2KrvzJkzk/pFdcTYCm1Ucw/gteQ2btwYxj766KMwFiXJdHd3h33Yqu+yZcvCGFuNT6knx64BRoqTwxwUBktsYo+ZXXPRFlt9fX1hn+i6+vzzz8M+E3llPwHgh+5+A2rbM99uZjcD+BWAp939agCHATw4gWMJIdpEXbF7jW+KP2cUPw7ghwB+W7S/AOCuloxQCNEUJro/+/RiB9f9AN4G8CWAEXc/9x5pF4ArWjNEIUQzmJDY3f2Mu68EcCWAVQCum+gJzGy1mQ2Y2cDBgwcThymEaJRJrca7+wiA3wP4cwDzzOzcisSVAHYHfda4e7+793d1dTU0WCFEOnXFbmaLzGxecftiAD8GMIia6P+quNsDAN5s1SCFEI0zEX+kB8ALZjYdtX8Or7r7f5nZZgAvm9k/AvgIwPONDITZLpFNkpqAwup0pfRLTaoYHR0NY7t27Qpjw8PDYWxkZKS0nVlvUXISwG05tpVTs+cqtfZbyrXDYNcHGyOz5aIagKz+39jYWGk7s/jqit3dNwC4saR9G2qf34UQfwLoG3RCZILELkQmSOxCZILELkQmSOxCZIKlZholnczsAIAdxZ9dAKbCV+o0jvPROM7nT20cS9291LOrVOznndhswN3723JyjUPjyHAcehsvRCZI7EJkQjvFvqaN5x6PxnE+Gsf5XDDjaNtndiFEtehtvBCZ0Baxm9ntZva5mW01s0faMYZiHNvNbKOZfWxmAxWed62Z7TezTePaFpjZ22b2RfF7fpvG8biZ7S7m5GMzu6OCcfSa2e/NbLOZfWpmf1O0VzonZByVzomZzTazP5rZJ8U4/qFov8rM3i9084qZxSluZbh7pT8ApqNW1qoPwEwAnwBYUfU4irFsB9DVhvP+AMBNADaNa/snAI8Utx8B8Ks2jeNxAH9b8Xz0ALipuN0JYAuAFVXPCRlHpXMCwAB0FLdnAHgfwM0AXgVwb9H+rwD+ejLHbccr+yoAW919m9dKT78M4M42jKNtuPu7AL7+TvOdqBXuBCoq4BmMo3LcfdjdPyxuj6FWHOUKVDwnZByV4jWaXuS1HWK/AsDQuL/bWazSAfzOzNab2eo2jeEc3e5+rirFXgBxtYnW85CZbSje5rf848R4zGwZavUT3kcb5+Q74wAqnpNWFHnNfYHuFne/CcBfAviFmf2g3QMCav/ZUftH1A6eBbActT0ChgE8WdWJzawDwGsAHnb388r4VDknJeOofE68gSKvEe0Q+24AveP+DotVthp331383g/gDbS38s4+M+sBgOL3/nYMwt33FRfaWQDPoaI5MbMZqAnsRXd/vWiufE7KxtGuOSnOPekirxHtEPsHAK4pVhZnArgXwLqqB2Fml5hZ57nbAH4CYBPv1VLWoVa4E2hjAc9z4iq4GxXMidWKtz0PYNDdnxoXqnROonFUPSctK/Ja1Qrjd1Yb70BtpfNLAH/XpjH0oeYEfALg0yrHAeAl1N4OnkLts9eDqO2Z9w6ALwD8L4AFbRrHvwPYCGADamLrqWAct6D2Fn0DgI+LnzuqnhMyjkrnBMCfoVbEdQNq/1j+ftw1+0cAWwH8J4BZkzmuvkEnRCbkvkAnRDZI7EJkgsQuRCZI7EJkgsQuRCZI7EJkgsQuRCZI7EJkwv8BtS85YcIsbQsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp2j51DkvQsF",
        "outputId": "88d12131-f45b-4880-d51e-ec41b6d74ee2"
      },
      "source": [
        "print(f['X_train'].shape)\r\n",
        "print(f['y_train'].shape)\r\n",
        "print(f['X_test'].shape)\r\n",
        "print(f['y_test'].shape)\r\n",
        "print(f['X_val'].shape)\r\n",
        "print(f['y_val'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 32, 32)\n",
            "(42000,)\n",
            "(18000, 32, 32)\n",
            "(18000,)\n",
            "(60000, 32, 32)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaoAaJcOhGIS"
      },
      "source": [
        "x_train = f['X_val'].value.reshape(f['X_val'].shape[0], 32, 32,1)\r\n",
        "x_val = f['X_train'].value.reshape(f['X_train'].shape[0], 32, 32,1)\r\n",
        "x_test = f['X_test'].value.reshape(f['X_test'].shape[0], 32, 32,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQGbeNjbo9XW"
      },
      "source": [
        "y_train = f['y_val']\r\n",
        "y_val = f['y_train']\r\n",
        "y_test = f['y_test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8fvsWi88N6G",
        "outputId": "4615b663-9337-46ba-8502-920e5bf2def6"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 32, 32, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxHopE-6ZRsv"
      },
      "source": [
        "x_train = x_train.astype('float32')/255\r\n",
        "x_val = x_val.astype('float32')/255\r\n",
        "x_test = x_test.astype('float32')/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz47AFUVhodM",
        "outputId": "50c05662-cbf8-4a39-91c4-94e0ce77c5b9"
      },
      "source": [
        "print(\"x_train shape:\", x_train.shape)\r\n",
        "print(\"Images in x_train:\", x_train.shape[0])\r\n",
        "print(\"Images in x_test:\", x_test.shape[0])\r\n",
        "print(\"Max value in x_train:\", x_test.max())\r\n",
        "print(\"Min value in x_train:\", x_test.min())\r\n",
        "print(\"Max value in x_test:\", x_test.max())\r\n",
        "print(\"Min value in x_test:\", x_test.min())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 32, 32, 1)\n",
            "Images in x_train: 60000\n",
            "Images in x_test: 18000\n",
            "Max value in x_train: 0.9999\n",
            "Min value in x_train: 0.0\n",
            "Max value in x_test: 0.9999\n",
            "Min value in x_test: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXODZAmIh-hk"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\r\n",
        "\r\n",
        "y_train = to_categorical(y_train, num_classes=10)\r\n",
        "y_val = to_categorical(y_val, num_classes=10)\r\n",
        "y_test = to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxCwUj3Gitoo",
        "outputId": "e0b7bb2c-8afc-4a30-9131-8add5f54b0ae"
      },
      "source": [
        "print(\"Shape of y_train:\", y_train.shape)\r\n",
        "print(\"One value of y_train:\", y_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of y_train: (60000, 10)\n",
            "One value of y_train: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXFQmCfziL7Y"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Flatten, Dense\r\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "model = Sequential()\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(128, activation=\"relu\"))\r\n",
        "model.add(Dense(128, activation=\"relu\"))\r\n",
        "model.add(Dense(128, activation=\"relu\"))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgGHEV1hp1hr",
        "outputId": "1da73ead-e999-471f-c266-84503128efe6"
      },
      "source": [
        "# Compile the model\r\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"sgd\")\r\n",
        "\r\n",
        "# Fit the model\r\n",
        "model.fit(x=x_train, y=y_train, batch_size=32, epochs=100, validation_data=(x_val, y_val))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 2.2899 - accuracy: 0.1306 - val_loss: 2.1699 - val_accuracy: 0.2484\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.0351 - accuracy: 0.3076 - val_loss: 1.6065 - val_accuracy: 0.4718\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5048 - accuracy: 0.5153 - val_loss: 1.4135 - val_accuracy: 0.5417\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.2392 - accuracy: 0.6074 - val_loss: 1.0813 - val_accuracy: 0.6721\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1171 - accuracy: 0.6507 - val_loss: 1.0210 - val_accuracy: 0.6828\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.0233 - accuracy: 0.6814 - val_loss: 1.0126 - val_accuracy: 0.6743\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9447 - accuracy: 0.7123 - val_loss: 0.9377 - val_accuracy: 0.7035\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9022 - accuracy: 0.7242 - val_loss: 0.8807 - val_accuracy: 0.7280\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.8461 - accuracy: 0.7409 - val_loss: 0.8495 - val_accuracy: 0.7385\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8187 - accuracy: 0.7489 - val_loss: 0.7748 - val_accuracy: 0.7620\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7756 - accuracy: 0.7639 - val_loss: 0.7400 - val_accuracy: 0.7724\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7548 - accuracy: 0.7677 - val_loss: 0.7263 - val_accuracy: 0.7770\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7361 - accuracy: 0.7760 - val_loss: 0.7951 - val_accuracy: 0.7571\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7197 - accuracy: 0.7789 - val_loss: 0.6558 - val_accuracy: 0.8032\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6847 - accuracy: 0.7919 - val_loss: 0.6526 - val_accuracy: 0.8029\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6783 - accuracy: 0.7933 - val_loss: 0.6384 - val_accuracy: 0.8062\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6567 - accuracy: 0.8010 - val_loss: 0.6301 - val_accuracy: 0.8067\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6377 - accuracy: 0.8056 - val_loss: 0.5994 - val_accuracy: 0.8170\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6344 - accuracy: 0.8058 - val_loss: 0.5891 - val_accuracy: 0.8210\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.6123 - accuracy: 0.8138 - val_loss: 0.5887 - val_accuracy: 0.8181\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5997 - accuracy: 0.8150 - val_loss: 0.5651 - val_accuracy: 0.8284\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5813 - accuracy: 0.8232 - val_loss: 0.5638 - val_accuracy: 0.8267\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5750 - accuracy: 0.8241 - val_loss: 0.5648 - val_accuracy: 0.8269\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5729 - accuracy: 0.8257 - val_loss: 0.5690 - val_accuracy: 0.8254\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5555 - accuracy: 0.8295 - val_loss: 0.5676 - val_accuracy: 0.8232\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5365 - accuracy: 0.8374 - val_loss: 0.5274 - val_accuracy: 0.8381\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5310 - accuracy: 0.8389 - val_loss: 0.5767 - val_accuracy: 0.8195\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5275 - accuracy: 0.8389 - val_loss: 0.5032 - val_accuracy: 0.8448\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5202 - accuracy: 0.8403 - val_loss: 0.4907 - val_accuracy: 0.8505\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5106 - accuracy: 0.8414 - val_loss: 0.4902 - val_accuracy: 0.8487\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5025 - accuracy: 0.8464 - val_loss: 0.4860 - val_accuracy: 0.8480\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4900 - accuracy: 0.8502 - val_loss: 0.4649 - val_accuracy: 0.8586\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4873 - accuracy: 0.8511 - val_loss: 0.5154 - val_accuracy: 0.8395\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4806 - accuracy: 0.8523 - val_loss: 0.4476 - val_accuracy: 0.8625\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4694 - accuracy: 0.8547 - val_loss: 0.4704 - val_accuracy: 0.8555\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4723 - accuracy: 0.8544 - val_loss: 0.4551 - val_accuracy: 0.8590\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4678 - accuracy: 0.8566 - val_loss: 0.4475 - val_accuracy: 0.8634\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4672 - accuracy: 0.8575 - val_loss: 0.5221 - val_accuracy: 0.8395\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4549 - accuracy: 0.8613 - val_loss: 0.4700 - val_accuracy: 0.8511\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4450 - accuracy: 0.8614 - val_loss: 0.4549 - val_accuracy: 0.8580\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4310 - accuracy: 0.8674 - val_loss: 0.4151 - val_accuracy: 0.8732\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4400 - accuracy: 0.8662 - val_loss: 0.4414 - val_accuracy: 0.8629\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4322 - accuracy: 0.8672 - val_loss: 0.3993 - val_accuracy: 0.8778\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4283 - accuracy: 0.8685 - val_loss: 0.3976 - val_accuracy: 0.8764\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4213 - accuracy: 0.8694 - val_loss: 0.4004 - val_accuracy: 0.8771\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4153 - accuracy: 0.8702 - val_loss: 0.4540 - val_accuracy: 0.8587\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4096 - accuracy: 0.8743 - val_loss: 0.3988 - val_accuracy: 0.8765\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4033 - accuracy: 0.8740 - val_loss: 0.4000 - val_accuracy: 0.8761\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4022 - accuracy: 0.8763 - val_loss: 0.4289 - val_accuracy: 0.8640\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3997 - accuracy: 0.8752 - val_loss: 0.3878 - val_accuracy: 0.8789\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3934 - accuracy: 0.8785 - val_loss: 0.4139 - val_accuracy: 0.8697\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3981 - accuracy: 0.8744 - val_loss: 0.3656 - val_accuracy: 0.8849\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3872 - accuracy: 0.8798 - val_loss: 0.3572 - val_accuracy: 0.8897\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3857 - accuracy: 0.8811 - val_loss: 0.3790 - val_accuracy: 0.8818\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3808 - accuracy: 0.8797 - val_loss: 0.3842 - val_accuracy: 0.8790\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3797 - accuracy: 0.8800 - val_loss: 0.3555 - val_accuracy: 0.8900\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3710 - accuracy: 0.8840 - val_loss: 0.3580 - val_accuracy: 0.8876\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3716 - accuracy: 0.8818 - val_loss: 0.3606 - val_accuracy: 0.8871\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3619 - accuracy: 0.8860 - val_loss: 0.3324 - val_accuracy: 0.8969\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3608 - accuracy: 0.8850 - val_loss: 0.3439 - val_accuracy: 0.8930\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3590 - accuracy: 0.8860 - val_loss: 0.4022 - val_accuracy: 0.8708\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3591 - accuracy: 0.8878 - val_loss: 0.3306 - val_accuracy: 0.8973\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3480 - accuracy: 0.8904 - val_loss: 0.3500 - val_accuracy: 0.8878\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3493 - accuracy: 0.8902 - val_loss: 0.3196 - val_accuracy: 0.9011\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3393 - accuracy: 0.8942 - val_loss: 0.3355 - val_accuracy: 0.8961\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3469 - accuracy: 0.8906 - val_loss: 0.3154 - val_accuracy: 0.9023\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3424 - accuracy: 0.8928 - val_loss: 0.3400 - val_accuracy: 0.8928\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3396 - accuracy: 0.8940 - val_loss: 0.3285 - val_accuracy: 0.8962\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3331 - accuracy: 0.8966 - val_loss: 0.3208 - val_accuracy: 0.8986\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3294 - accuracy: 0.8960 - val_loss: 0.3082 - val_accuracy: 0.9043\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3269 - accuracy: 0.8955 - val_loss: 0.3007 - val_accuracy: 0.9074\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3265 - accuracy: 0.8963 - val_loss: 0.2939 - val_accuracy: 0.9090\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3150 - accuracy: 0.9002 - val_loss: 0.3021 - val_accuracy: 0.9055\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3244 - accuracy: 0.8982 - val_loss: 0.3037 - val_accuracy: 0.9049\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3184 - accuracy: 0.8988 - val_loss: 0.2886 - val_accuracy: 0.9095\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3144 - accuracy: 0.9006 - val_loss: 0.3151 - val_accuracy: 0.9002\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3142 - accuracy: 0.9029 - val_loss: 0.2822 - val_accuracy: 0.9116\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3093 - accuracy: 0.9010 - val_loss: 0.2903 - val_accuracy: 0.9098\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3013 - accuracy: 0.9044 - val_loss: 0.2779 - val_accuracy: 0.9134\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2975 - accuracy: 0.9074 - val_loss: 0.3197 - val_accuracy: 0.8952\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2974 - accuracy: 0.9044 - val_loss: 0.3150 - val_accuracy: 0.8985\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3022 - accuracy: 0.9045 - val_loss: 0.3236 - val_accuracy: 0.8956\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2904 - accuracy: 0.9073 - val_loss: 0.2907 - val_accuracy: 0.9074\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2877 - accuracy: 0.9068 - val_loss: 0.2854 - val_accuracy: 0.9079\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2878 - accuracy: 0.9092 - val_loss: 0.2607 - val_accuracy: 0.9211\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2807 - accuracy: 0.9111 - val_loss: 0.2736 - val_accuracy: 0.9137\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2822 - accuracy: 0.9106 - val_loss: 0.3001 - val_accuracy: 0.9033\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2793 - accuracy: 0.9105 - val_loss: 0.2768 - val_accuracy: 0.9106\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2775 - accuracy: 0.9121 - val_loss: 0.3063 - val_accuracy: 0.9007\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2752 - accuracy: 0.9114 - val_loss: 0.2528 - val_accuracy: 0.9202\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2717 - accuracy: 0.9130 - val_loss: 0.2925 - val_accuracy: 0.9061\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2706 - accuracy: 0.9144 - val_loss: 0.2606 - val_accuracy: 0.9185\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2713 - accuracy: 0.9154 - val_loss: 0.2420 - val_accuracy: 0.9241\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2674 - accuracy: 0.9162 - val_loss: 0.2401 - val_accuracy: 0.9252\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2673 - accuracy: 0.9148 - val_loss: 0.2464 - val_accuracy: 0.9229\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2719 - accuracy: 0.9152 - val_loss: 0.2414 - val_accuracy: 0.9237\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2588 - accuracy: 0.9183 - val_loss: 0.2757 - val_accuracy: 0.9125\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2631 - accuracy: 0.9158 - val_loss: 0.2361 - val_accuracy: 0.9254\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2517 - accuracy: 0.9203 - val_loss: 0.2427 - val_accuracy: 0.9240\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2531 - accuracy: 0.9195 - val_loss: 0.2295 - val_accuracy: 0.9284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f03a81f94d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnv5IIxHmSqG",
        "outputId": "8c0492a6-2bdb-40d6-8199-329b270acfce"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Flatten, Dense\r\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "model = Sequential()\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(256, activation=\"relu\"))\r\n",
        "model.add(Dense(256, activation=\"relu\"))\r\n",
        "model.add(Dense(256, activation=\"relu\"))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "\r\n",
        "# Compile the model\r\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"sgd\")\r\n",
        "\r\n",
        "# Fit the model\r\n",
        "model.fit(x=x_train, y=y_train, batch_size=32, epochs=100, validation_data=(x_val, y_val))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 2.2800 - accuracy: 0.1483 - val_loss: 2.0630 - val_accuracy: 0.3255\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.8734 - accuracy: 0.3963 - val_loss: 1.4707 - val_accuracy: 0.5343\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.3921 - accuracy: 0.5605 - val_loss: 1.2490 - val_accuracy: 0.6055\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1734 - accuracy: 0.6353 - val_loss: 1.0427 - val_accuracy: 0.6852\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.0490 - accuracy: 0.6764 - val_loss: 0.9707 - val_accuracy: 0.6984\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9640 - accuracy: 0.7018 - val_loss: 0.9137 - val_accuracy: 0.7186\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9127 - accuracy: 0.7186 - val_loss: 0.8101 - val_accuracy: 0.7563\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8602 - accuracy: 0.7353 - val_loss: 0.8189 - val_accuracy: 0.7447\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8132 - accuracy: 0.7527 - val_loss: 0.7512 - val_accuracy: 0.7724\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7668 - accuracy: 0.7655 - val_loss: 0.7479 - val_accuracy: 0.7686\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7358 - accuracy: 0.7762 - val_loss: 0.7255 - val_accuracy: 0.7768\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7010 - accuracy: 0.7849 - val_loss: 0.6762 - val_accuracy: 0.7964\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6812 - accuracy: 0.7928 - val_loss: 0.6558 - val_accuracy: 0.8017\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6520 - accuracy: 0.8028 - val_loss: 0.6692 - val_accuracy: 0.7954\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6248 - accuracy: 0.8077 - val_loss: 0.5905 - val_accuracy: 0.8217\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6208 - accuracy: 0.8119 - val_loss: 0.5858 - val_accuracy: 0.8224\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5971 - accuracy: 0.8201 - val_loss: 0.5551 - val_accuracy: 0.8314\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5780 - accuracy: 0.8265 - val_loss: 0.5311 - val_accuracy: 0.8421\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5633 - accuracy: 0.8279 - val_loss: 0.5352 - val_accuracy: 0.8390\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5601 - accuracy: 0.8301 - val_loss: 0.5504 - val_accuracy: 0.8318\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5440 - accuracy: 0.8348 - val_loss: 0.4923 - val_accuracy: 0.8524\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5276 - accuracy: 0.8396 - val_loss: 0.4971 - val_accuracy: 0.8516\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5186 - accuracy: 0.8421 - val_loss: 0.4914 - val_accuracy: 0.8511\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5047 - accuracy: 0.8451 - val_loss: 0.4867 - val_accuracy: 0.8502\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4926 - accuracy: 0.8503 - val_loss: 0.4404 - val_accuracy: 0.8673\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4860 - accuracy: 0.8534 - val_loss: 0.4834 - val_accuracy: 0.8532\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4786 - accuracy: 0.8543 - val_loss: 0.4471 - val_accuracy: 0.8655\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4713 - accuracy: 0.8558 - val_loss: 0.4556 - val_accuracy: 0.8611\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4531 - accuracy: 0.8610 - val_loss: 0.4359 - val_accuracy: 0.8680\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4492 - accuracy: 0.8626 - val_loss: 0.4239 - val_accuracy: 0.8690\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4445 - accuracy: 0.8658 - val_loss: 0.4409 - val_accuracy: 0.8655\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4357 - accuracy: 0.8674 - val_loss: 0.4025 - val_accuracy: 0.8786\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4237 - accuracy: 0.8675 - val_loss: 0.4011 - val_accuracy: 0.8782\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4165 - accuracy: 0.8712 - val_loss: 0.4037 - val_accuracy: 0.8773\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4068 - accuracy: 0.8750 - val_loss: 0.3757 - val_accuracy: 0.8862\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4020 - accuracy: 0.8774 - val_loss: 0.4134 - val_accuracy: 0.8728\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4016 - accuracy: 0.8776 - val_loss: 0.3776 - val_accuracy: 0.8845\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3919 - accuracy: 0.8802 - val_loss: 0.3858 - val_accuracy: 0.8814\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3887 - accuracy: 0.8799 - val_loss: 0.3619 - val_accuracy: 0.8907\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3739 - accuracy: 0.8845 - val_loss: 0.3690 - val_accuracy: 0.8857\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3739 - accuracy: 0.8866 - val_loss: 0.3495 - val_accuracy: 0.8932\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3692 - accuracy: 0.8852 - val_loss: 0.3525 - val_accuracy: 0.8906\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3584 - accuracy: 0.8902 - val_loss: 0.3522 - val_accuracy: 0.8901\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3589 - accuracy: 0.8918 - val_loss: 0.3139 - val_accuracy: 0.9063\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3441 - accuracy: 0.8926 - val_loss: 0.3973 - val_accuracy: 0.8736\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3489 - accuracy: 0.8912 - val_loss: 0.3158 - val_accuracy: 0.9032\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3358 - accuracy: 0.8960 - val_loss: 0.3184 - val_accuracy: 0.9029\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3371 - accuracy: 0.8957 - val_loss: 0.3290 - val_accuracy: 0.8979\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3226 - accuracy: 0.9025 - val_loss: 0.3175 - val_accuracy: 0.9017\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3274 - accuracy: 0.8979 - val_loss: 0.3636 - val_accuracy: 0.8824\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3277 - accuracy: 0.8979 - val_loss: 0.3021 - val_accuracy: 0.9071\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3184 - accuracy: 0.9015 - val_loss: 0.3057 - val_accuracy: 0.9060\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3109 - accuracy: 0.9033 - val_loss: 0.2971 - val_accuracy: 0.9078\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3092 - accuracy: 0.9053 - val_loss: 0.3115 - val_accuracy: 0.9014\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2983 - accuracy: 0.9085 - val_loss: 0.2791 - val_accuracy: 0.9136\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2918 - accuracy: 0.9099 - val_loss: 0.2882 - val_accuracy: 0.9107\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2967 - accuracy: 0.9086 - val_loss: 0.2798 - val_accuracy: 0.9142\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2832 - accuracy: 0.9118 - val_loss: 0.3042 - val_accuracy: 0.9029\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2858 - accuracy: 0.9116 - val_loss: 0.2483 - val_accuracy: 0.9251\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2749 - accuracy: 0.9144 - val_loss: 0.2813 - val_accuracy: 0.9109\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2745 - accuracy: 0.9153 - val_loss: 0.2548 - val_accuracy: 0.9214\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2633 - accuracy: 0.9189 - val_loss: 0.2570 - val_accuracy: 0.9199\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2643 - accuracy: 0.9176 - val_loss: 0.2457 - val_accuracy: 0.9236\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2612 - accuracy: 0.9194 - val_loss: 0.2404 - val_accuracy: 0.9267\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2521 - accuracy: 0.9203 - val_loss: 0.2300 - val_accuracy: 0.9290\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2557 - accuracy: 0.9210 - val_loss: 0.2318 - val_accuracy: 0.9275\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2471 - accuracy: 0.9233 - val_loss: 0.2321 - val_accuracy: 0.9288\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2440 - accuracy: 0.9239 - val_loss: 0.2265 - val_accuracy: 0.9302\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2411 - accuracy: 0.9256 - val_loss: 0.2324 - val_accuracy: 0.9275\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2426 - accuracy: 0.9243 - val_loss: 0.2472 - val_accuracy: 0.9215\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2348 - accuracy: 0.9267 - val_loss: 0.2201 - val_accuracy: 0.9316\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2291 - accuracy: 0.9285 - val_loss: 0.2325 - val_accuracy: 0.9290\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2275 - accuracy: 0.9299 - val_loss: 0.2112 - val_accuracy: 0.9350\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2172 - accuracy: 0.9309 - val_loss: 0.1953 - val_accuracy: 0.9420\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2194 - accuracy: 0.9318 - val_loss: 0.2288 - val_accuracy: 0.9292\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2187 - accuracy: 0.9319 - val_loss: 0.2078 - val_accuracy: 0.9352\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2122 - accuracy: 0.9328 - val_loss: 0.1974 - val_accuracy: 0.9395\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2085 - accuracy: 0.9346 - val_loss: 0.2273 - val_accuracy: 0.9276\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2082 - accuracy: 0.9336 - val_loss: 0.2066 - val_accuracy: 0.9338\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2025 - accuracy: 0.9379 - val_loss: 0.1993 - val_accuracy: 0.9383\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2041 - accuracy: 0.9360 - val_loss: 0.1927 - val_accuracy: 0.9399\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1994 - accuracy: 0.9375 - val_loss: 0.1924 - val_accuracy: 0.9398\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2018 - accuracy: 0.9353 - val_loss: 0.1893 - val_accuracy: 0.9397\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1940 - accuracy: 0.9394 - val_loss: 0.1805 - val_accuracy: 0.9434\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1847 - accuracy: 0.9422 - val_loss: 0.1756 - val_accuracy: 0.9468\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1827 - accuracy: 0.9439 - val_loss: 0.1788 - val_accuracy: 0.9442\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1858 - accuracy: 0.9416 - val_loss: 0.1896 - val_accuracy: 0.9392\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1804 - accuracy: 0.9444 - val_loss: 0.1716 - val_accuracy: 0.9466\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1761 - accuracy: 0.9451 - val_loss: 0.1900 - val_accuracy: 0.9403\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1766 - accuracy: 0.9437 - val_loss: 0.1577 - val_accuracy: 0.9519\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1697 - accuracy: 0.9465 - val_loss: 0.1765 - val_accuracy: 0.9429\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1672 - accuracy: 0.9470 - val_loss: 0.1627 - val_accuracy: 0.9493\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1666 - accuracy: 0.9473 - val_loss: 0.1454 - val_accuracy: 0.9554\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1621 - accuracy: 0.9498 - val_loss: 0.1571 - val_accuracy: 0.9510\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1596 - accuracy: 0.9494 - val_loss: 0.1625 - val_accuracy: 0.9480\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1579 - accuracy: 0.9496 - val_loss: 0.1330 - val_accuracy: 0.9605\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1556 - accuracy: 0.9506 - val_loss: 0.1557 - val_accuracy: 0.9519\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1490 - accuracy: 0.9545 - val_loss: 0.1244 - val_accuracy: 0.9637\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1471 - accuracy: 0.9528 - val_loss: 0.1215 - val_accuracy: 0.9645\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1459 - accuracy: 0.9537 - val_loss: 0.1319 - val_accuracy: 0.9609\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f038c79cd90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZSk7kAC1Iuh",
        "outputId": "d7e87430-b197-4b33-e5ba-0ff38451f0d3"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Flatten, Dense\r\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "model = Sequential()\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(256, activation=\"relu\"))\r\n",
        "model.add(Dense(256, activation=\"relu\"))\r\n",
        "model.add(Dense(256, activation=\"relu\"))\r\n",
        "model.add(Dense(256, activation=\"relu\"))\r\n",
        "model.add(Dense(10, activation=\"softmax\"))\r\n",
        "\r\n",
        "# Compile the model\r\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"sgd\")\r\n",
        "\r\n",
        "# Fit the model\r\n",
        "model.fit(x=x_train, y=y_train, batch_size=32, epochs=100, validation_data=(x_val, y_val))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 2.2809 - accuracy: 0.1458 - val_loss: 2.0248 - val_accuracy: 0.3208\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.8470 - accuracy: 0.3764 - val_loss: 1.4171 - val_accuracy: 0.5243\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 1.3745 - accuracy: 0.5520 - val_loss: 1.1218 - val_accuracy: 0.6529\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.1570 - accuracy: 0.6321 - val_loss: 1.0599 - val_accuracy: 0.6626\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.0270 - accuracy: 0.6777 - val_loss: 0.9073 - val_accuracy: 0.7208\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9430 - accuracy: 0.7052 - val_loss: 0.9206 - val_accuracy: 0.7026\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8886 - accuracy: 0.7212 - val_loss: 0.8244 - val_accuracy: 0.7395\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8416 - accuracy: 0.7391 - val_loss: 0.7769 - val_accuracy: 0.7632\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7975 - accuracy: 0.7509 - val_loss: 0.7168 - val_accuracy: 0.7790\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7611 - accuracy: 0.7630 - val_loss: 0.7170 - val_accuracy: 0.7771\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.7228 - accuracy: 0.7754 - val_loss: 0.7432 - val_accuracy: 0.7666\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6959 - accuracy: 0.7856 - val_loss: 0.6765 - val_accuracy: 0.7889\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6643 - accuracy: 0.7947 - val_loss: 0.6214 - val_accuracy: 0.8053\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6517 - accuracy: 0.7967 - val_loss: 0.6260 - val_accuracy: 0.8046\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6261 - accuracy: 0.8081 - val_loss: 0.6083 - val_accuracy: 0.8095\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6060 - accuracy: 0.8127 - val_loss: 0.5837 - val_accuracy: 0.8179\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5887 - accuracy: 0.8181 - val_loss: 0.5776 - val_accuracy: 0.8200\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5638 - accuracy: 0.8269 - val_loss: 0.5662 - val_accuracy: 0.8243\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5597 - accuracy: 0.8282 - val_loss: 0.5288 - val_accuracy: 0.8354\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5404 - accuracy: 0.8314 - val_loss: 0.4929 - val_accuracy: 0.8477\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5210 - accuracy: 0.8380 - val_loss: 0.5078 - val_accuracy: 0.8410\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5051 - accuracy: 0.8428 - val_loss: 0.4966 - val_accuracy: 0.8458\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4950 - accuracy: 0.8479 - val_loss: 0.5038 - val_accuracy: 0.8408\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4865 - accuracy: 0.8502 - val_loss: 0.4791 - val_accuracy: 0.8492\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4719 - accuracy: 0.8527 - val_loss: 0.4597 - val_accuracy: 0.8577\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4571 - accuracy: 0.8584 - val_loss: 0.4777 - val_accuracy: 0.8499\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4487 - accuracy: 0.8607 - val_loss: 0.4187 - val_accuracy: 0.8709\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4314 - accuracy: 0.8659 - val_loss: 0.4310 - val_accuracy: 0.8666\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4266 - accuracy: 0.8657 - val_loss: 0.4205 - val_accuracy: 0.8706\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4185 - accuracy: 0.8714 - val_loss: 0.4088 - val_accuracy: 0.8716\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4078 - accuracy: 0.8731 - val_loss: 0.4215 - val_accuracy: 0.8682\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4064 - accuracy: 0.8721 - val_loss: 0.3697 - val_accuracy: 0.8874\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3926 - accuracy: 0.8773 - val_loss: 0.3666 - val_accuracy: 0.8855\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3897 - accuracy: 0.8784 - val_loss: 0.3579 - val_accuracy: 0.8876\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3834 - accuracy: 0.8781 - val_loss: 0.3534 - val_accuracy: 0.8901\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3689 - accuracy: 0.8856 - val_loss: 0.3613 - val_accuracy: 0.8858\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3652 - accuracy: 0.8873 - val_loss: 0.3507 - val_accuracy: 0.8914\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3506 - accuracy: 0.8890 - val_loss: 0.3502 - val_accuracy: 0.8909\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3458 - accuracy: 0.8913 - val_loss: 0.3788 - val_accuracy: 0.8799\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3403 - accuracy: 0.8914 - val_loss: 0.3095 - val_accuracy: 0.9024\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3409 - accuracy: 0.8923 - val_loss: 0.3516 - val_accuracy: 0.8884\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3324 - accuracy: 0.8949 - val_loss: 0.3007 - val_accuracy: 0.9061\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3281 - accuracy: 0.8953 - val_loss: 0.2883 - val_accuracy: 0.9094\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3142 - accuracy: 0.9006 - val_loss: 0.3614 - val_accuracy: 0.8844\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3117 - accuracy: 0.9011 - val_loss: 0.2961 - val_accuracy: 0.9070\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3035 - accuracy: 0.9038 - val_loss: 0.2684 - val_accuracy: 0.9156\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3044 - accuracy: 0.9030 - val_loss: 0.2846 - val_accuracy: 0.9101\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2908 - accuracy: 0.9081 - val_loss: 0.2927 - val_accuracy: 0.9068\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2897 - accuracy: 0.9083 - val_loss: 0.3211 - val_accuracy: 0.8957\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2882 - accuracy: 0.9066 - val_loss: 0.2640 - val_accuracy: 0.9164\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2734 - accuracy: 0.9123 - val_loss: 0.2682 - val_accuracy: 0.9155\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2736 - accuracy: 0.9127 - val_loss: 0.3035 - val_accuracy: 0.9016\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2698 - accuracy: 0.9151 - val_loss: 0.2441 - val_accuracy: 0.9224\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2568 - accuracy: 0.9159 - val_loss: 0.2398 - val_accuracy: 0.9249\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2504 - accuracy: 0.9212 - val_loss: 0.2369 - val_accuracy: 0.9245\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2463 - accuracy: 0.9218 - val_loss: 0.2319 - val_accuracy: 0.9266\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2502 - accuracy: 0.9204 - val_loss: 0.2323 - val_accuracy: 0.9252\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2414 - accuracy: 0.9225 - val_loss: 0.2422 - val_accuracy: 0.9223\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2372 - accuracy: 0.9244 - val_loss: 0.2077 - val_accuracy: 0.9338\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2290 - accuracy: 0.9266 - val_loss: 0.2357 - val_accuracy: 0.9232\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2234 - accuracy: 0.9291 - val_loss: 0.2093 - val_accuracy: 0.9326\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2171 - accuracy: 0.9314 - val_loss: 0.2041 - val_accuracy: 0.9351\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2168 - accuracy: 0.9307 - val_loss: 0.1814 - val_accuracy: 0.9446\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2063 - accuracy: 0.9329 - val_loss: 0.2498 - val_accuracy: 0.9189\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2118 - accuracy: 0.9322 - val_loss: 0.1964 - val_accuracy: 0.9368\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2047 - accuracy: 0.9358 - val_loss: 0.1761 - val_accuracy: 0.9459\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1957 - accuracy: 0.9369 - val_loss: 0.1796 - val_accuracy: 0.9422\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1907 - accuracy: 0.9373 - val_loss: 0.1952 - val_accuracy: 0.9369\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1878 - accuracy: 0.9396 - val_loss: 0.1715 - val_accuracy: 0.9457\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1846 - accuracy: 0.9427 - val_loss: 0.1841 - val_accuracy: 0.9396\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1835 - accuracy: 0.9394 - val_loss: 0.1518 - val_accuracy: 0.9525\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1763 - accuracy: 0.9431 - val_loss: 0.1719 - val_accuracy: 0.9441\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1729 - accuracy: 0.9450 - val_loss: 0.1821 - val_accuracy: 0.9403\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1729 - accuracy: 0.9426 - val_loss: 0.1559 - val_accuracy: 0.9495\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1656 - accuracy: 0.9455 - val_loss: 0.1521 - val_accuracy: 0.9520\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1560 - accuracy: 0.9497 - val_loss: 0.1379 - val_accuracy: 0.9573\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1520 - accuracy: 0.9511 - val_loss: 0.1485 - val_accuracy: 0.9513\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1624 - accuracy: 0.9476 - val_loss: 0.1540 - val_accuracy: 0.9514\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1522 - accuracy: 0.9506 - val_loss: 0.2010 - val_accuracy: 0.9342\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1533 - accuracy: 0.9499 - val_loss: 0.1254 - val_accuracy: 0.9603\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1438 - accuracy: 0.9541 - val_loss: 0.1547 - val_accuracy: 0.9499\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1455 - accuracy: 0.9533 - val_loss: 0.1537 - val_accuracy: 0.9492\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1348 - accuracy: 0.9563 - val_loss: 0.1519 - val_accuracy: 0.9480\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1323 - accuracy: 0.9570 - val_loss: 0.1106 - val_accuracy: 0.9657\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1279 - accuracy: 0.9579 - val_loss: 0.1196 - val_accuracy: 0.9622\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1278 - accuracy: 0.9588 - val_loss: 0.1349 - val_accuracy: 0.9558\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1250 - accuracy: 0.9593 - val_loss: 0.1499 - val_accuracy: 0.9507\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1222 - accuracy: 0.9606 - val_loss: 0.1378 - val_accuracy: 0.9541\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1237 - accuracy: 0.9606 - val_loss: 0.1553 - val_accuracy: 0.9470\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1277 - accuracy: 0.9580 - val_loss: 0.1103 - val_accuracy: 0.9640\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1175 - accuracy: 0.9621 - val_loss: 0.1267 - val_accuracy: 0.9574\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1081 - accuracy: 0.9658 - val_loss: 0.1131 - val_accuracy: 0.9630\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1071 - accuracy: 0.9651 - val_loss: 0.0887 - val_accuracy: 0.9717\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1072 - accuracy: 0.9646 - val_loss: 0.1394 - val_accuracy: 0.9526\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1105 - accuracy: 0.9634 - val_loss: 0.0912 - val_accuracy: 0.9719\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1044 - accuracy: 0.9657 - val_loss: 0.0857 - val_accuracy: 0.9734\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0994 - accuracy: 0.9674 - val_loss: 0.1038 - val_accuracy: 0.9656\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0972 - accuracy: 0.9689 - val_loss: 0.0887 - val_accuracy: 0.9720\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0903 - accuracy: 0.9706 - val_loss: 0.0809 - val_accuracy: 0.9752\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0879 - accuracy: 0.9722 - val_loss: 0.0763 - val_accuracy: 0.9761\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f03a804c810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzsVa84Vspmh"
      },
      "source": [
        "def create_model(lr, Lambda):\r\n",
        "\r\n",
        "    ## hyperparameters\r\n",
        "    learning_rate = lr\r\n",
        "    hidden_nodes = 256\r\n",
        "    output_nodes = 10\r\n",
        "        \r\n",
        "    model = Sequential()\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(hidden_nodes, activation='relu'))\r\n",
        "    model.add(Dense(hidden_nodes, activation='relu'))\r\n",
        "    model.add(Dense(output_nodes, kernel_regularizer=regularizers.l2(Lambda)))\r\n",
        "    \r\n",
        "    sgd = optimizers.SGD(lr=lr, decay=1e-7, momentum=0.9)\r\n",
        "    # Compile model\r\n",
        "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"],optimizer=\"sgd\")\r\n",
        "    return model"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmAXGEiMvW6O"
      },
      "source": [
        "model = KerasClassifier(build_fn=create_model, epochs=30, batch_size=10)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NE5ua_pevmMX",
        "outputId": "794355b8-5530-4922-f335-c97272765192"
      },
      "source": [
        "# define the grid search parameters\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from tensorflow.keras import regularizers, optimizers\r\n",
        "lr = [1e-2,1e-1] #1e-5,1e-4,1e-3,\r\n",
        "Lambda = [1e-5]#,1e-6,1e-4,1e-3\r\n",
        "\r\n",
        "param_grid = dict(lr=lr,Lambda=Lambda)\r\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=2)\r\n",
        "grid_result = grid.fit(x_train, y_train)\r\n",
        "# summarize results\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 10.4621 - accuracy: 0.2008\n",
            "Epoch 2/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 10.1207 - accuracy: 0.2012\n",
            "Epoch 3/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 10.0146 - accuracy: 0.1983\n",
            "Epoch 4/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 10.0587 - accuracy: 0.1974\n",
            "Epoch 5/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 10.1058 - accuracy: 0.1997\n",
            "Epoch 6/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 10.0722 - accuracy: 0.1992\n",
            "Epoch 7/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 10.0930 - accuracy: 0.1988\n",
            "Epoch 8/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 10.0431 - accuracy: 0.1942\n",
            "Epoch 9/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 10.0938 - accuracy: 0.1974\n",
            "Epoch 10/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 10.1029 - accuracy: 0.2037\n",
            "Epoch 11/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 10.1756 - accuracy: 0.2028\n",
            "Epoch 12/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 10.1777 - accuracy: 0.2022\n",
            "Epoch 13/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 10.1074 - accuracy: 0.2017\n",
            "Epoch 14/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 10.1918 - accuracy: 0.2033\n",
            "Epoch 15/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 10.1017 - accuracy: 0.2010\n",
            "Epoch 16/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 10.0108 - accuracy: 0.2023\n",
            "Epoch 17/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 10.0117 - accuracy: 0.2003\n",
            "Epoch 18/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 10.0824 - accuracy: 0.1974\n",
            "Epoch 19/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 10.1343 - accuracy: 0.2009\n",
            "Epoch 20/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 10.0924 - accuracy: 0.1982\n",
            "Epoch 21/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 10.1239 - accuracy: 0.2041\n",
            "Epoch 22/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 10.1117 - accuracy: 0.2004\n",
            "Epoch 23/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 10.0786 - accuracy: 0.1966\n",
            "Epoch 24/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 10.1183 - accuracy: 0.2037\n",
            "Epoch 25/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 10.0963 - accuracy: 0.1996\n",
            "Epoch 26/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 10.1258 - accuracy: 0.2006\n",
            "Epoch 27/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 10.2311 - accuracy: 0.2031\n",
            "Epoch 28/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 10.0804 - accuracy: 0.2026\n",
            "Epoch 29/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 10.1313 - accuracy: 0.2011\n",
            "Epoch 30/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 10.1484 - accuracy: 0.1986\n",
            "3000/3000 [==============================] - 4s 1ms/step - loss: 8.6766 - accuracy: 0.0000e+00\n",
            "Epoch 1/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 8.8489 - accuracy: 0.1344\n",
            "Epoch 2/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 8.0573 - accuracy: 0.1343\n",
            "Epoch 3/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 8.5013 - accuracy: 0.1372\n",
            "Epoch 4/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 8.5670 - accuracy: 0.1364\n",
            "Epoch 5/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 8.6470 - accuracy: 0.1339\n",
            "Epoch 6/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 8.6692 - accuracy: 0.1357\n",
            "Epoch 7/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 8.6630 - accuracy: 0.1325\n",
            "Epoch 8/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 8.6958 - accuracy: 0.1352\n",
            "Epoch 9/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 8.7303 - accuracy: 0.1322\n",
            "Epoch 10/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 8.6496 - accuracy: 0.1330\n",
            "Epoch 11/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 8.7415 - accuracy: 0.1334\n",
            "Epoch 12/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 8.5831 - accuracy: 0.1333\n",
            "Epoch 13/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 8.7078 - accuracy: 0.1338\n",
            "Epoch 14/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 8.6791 - accuracy: 0.1364\n",
            "Epoch 15/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 8.5988 - accuracy: 0.1346\n",
            "Epoch 16/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 8.7598 - accuracy: 0.1353\n",
            "Epoch 17/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 8.7307 - accuracy: 0.1344\n",
            "Epoch 18/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 8.7347 - accuracy: 0.1364\n",
            "Epoch 19/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 8.7881 - accuracy: 0.1350\n",
            "Epoch 20/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 8.6497 - accuracy: 0.1335\n",
            "Epoch 21/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 8.7709 - accuracy: 0.1310\n",
            "Epoch 22/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 8.7065 - accuracy: 0.1315\n",
            "Epoch 23/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 8.6752 - accuracy: 0.1344\n",
            "Epoch 24/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 8.6966 - accuracy: 0.1305\n",
            "Epoch 25/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 8.6623 - accuracy: 0.1360\n",
            "Epoch 26/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 8.6532 - accuracy: 0.1351\n",
            "Epoch 27/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 8.5795 - accuracy: 0.1303\n",
            "Epoch 28/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 8.7296 - accuracy: 0.1338\n",
            "Epoch 29/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 8.6784 - accuracy: 0.1341\n",
            "Epoch 30/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 8.7440 - accuracy: 0.1339\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 7.1878 - accuracy: 0.0667\n",
            "Epoch 1/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 7.9186 - accuracy: 0.1053\n",
            "Epoch 2/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 7.5664 - accuracy: 0.1078\n",
            "Epoch 3/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: nan - accuracy: 0.0858\n",
            "Epoch 4/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: nan - accuracy: 0.0673\n",
            "Epoch 5/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: nan - accuracy: 0.0689\n",
            "Epoch 6/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: nan - accuracy: 0.0662\n",
            "Epoch 7/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: nan - accuracy: 0.0684\n",
            "Epoch 8/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: nan - accuracy: 0.0676\n",
            "Epoch 9/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: nan - accuracy: 0.0665\n",
            "Epoch 10/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: nan - accuracy: 0.0662\n",
            "Epoch 11/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: nan - accuracy: 0.0656\n",
            "Epoch 12/30\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: nan - accuracy: 0.0665\n",
            "Epoch 13/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: nan - accuracy: 0.0652\n",
            "Epoch 14/30\n",
            " 604/3000 [=====>........................] - ETA: 4s - loss: nan - accuracy: 0.0595"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-0a596b456cb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}